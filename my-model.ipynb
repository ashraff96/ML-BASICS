{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a20f53",
   "metadata": {},
   "source": [
    "# Bank Marketing Campaign Success Prediction\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook presents a comprehensive analysis of bank marketing campaign data to predict customer subscription to term deposits. The dataset contains customer demographic information, financial details, and previous campaign interaction history. Our objective is to build a predictive model that can identify customers most likely to subscribe to a term deposit product.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Banks invest significant resources in marketing campaigns to promote their financial products. The ability to predict which customers are most likely to respond positively to marketing efforts can dramatically improve campaign efficiency and return on investment. This binary classification problem aims to predict whether a customer will subscribe to a term deposit based on their profile and interaction history.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset consists of the following components:\n",
    "- Training data: 750,000 customer records with known outcomes\n",
    "- Test data: 250,000 customer records for prediction\n",
    "- Target variable: Binary indicator (0/1) for term deposit subscription\n",
    "- Features: 16 attributes covering demographics, financial status, and campaign history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04abf8",
   "metadata": {},
   "source": [
    "## Library Imports and Configuration\n",
    "\n",
    "We begin by importing essential libraries for data manipulation, visualization, and statistical analysis. Each library serves a specific purpose in our exploratory data analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, pearsonr\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuration for better visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ac354",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Inspection\n",
    "\n",
    "The first step in any data science project is to load and examine the structure of our dataset. We will load both training and test datasets and perform initial inspection to understand the data types, missing values, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"Training Dataset Shape:\", train_df.shape)\n",
    "print(\"Test Dataset Shape:\", test_df.shape)\n",
    "print(\"Sample Submission Shape:\", sample_submission.shape)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Display first few rows of training data\n",
    "print(\"First 5 rows of training dataset:\")\n",
    "print(train_df.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Display first few rows of test data\n",
    "print(\"First 5 rows of test dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5703a",
   "metadata": {},
   "source": [
    "## Data Structure and Quality Assessment\n",
    "\n",
    "Understanding the structure and quality of our data is crucial for effective analysis. We will examine data types, identify missing values, and assess the overall quality of each feature in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d033c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed information about the dataset structure\n",
    "print(\"TRAINING DATASET INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "print(train_df.info())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "missing_train = train_df.isnull().sum()\n",
    "missing_test = test_df.isnull().sum()\n",
    "\n",
    "# Create separate analysis for train and test datasets\n",
    "print(\"Training Dataset Missing Values:\")\n",
    "print(\"-\" * 30)\n",
    "for feature in train_df.columns:\n",
    "    missing_count = missing_train[feature]\n",
    "    missing_pct = (missing_count / len(train_df)) * 100\n",
    "    print(f\"{feature:15}: {missing_count:6,} ({missing_pct:5.2f}%)\")\n",
    "\n",
    "print(\"\\nTest Dataset Missing Values:\")\n",
    "print(\"-\" * 30)\n",
    "for feature in test_df.columns:\n",
    "    missing_count = missing_test[feature]\n",
    "    missing_pct = (missing_count / len(test_df)) * 100\n",
    "    print(f\"{feature:15}: {missing_count:6,} ({missing_pct:5.2f}%)\")\n",
    "\n",
    "# Summary comparison (only for features present in both datasets)\n",
    "common_features = [col for col in train_df.columns if col in test_df.columns]\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Feature': common_features,\n",
    "    'Train_Missing': [missing_train[col] for col in common_features],\n",
    "    'Train_Missing_%': [(missing_train[col] / len(train_df) * 100).round(2) for col in common_features],\n",
    "    'Test_Missing': [missing_test[col] for col in common_features],\n",
    "    'Test_Missing_%': [(missing_test[col] / len(test_df) * 100).round(2) for col in common_features]\n",
    "})\n",
    "\n",
    "print(\"\\nMissing Values Summary (Common Features):\")\n",
    "print(\"-\" * 50)\n",
    "print(missing_summary)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Data types summary\n",
    "print(\"DATA TYPES SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(train_df.dtypes.value_counts())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Basic statistics for numerical features\n",
    "print(\"NUMERICAL FEATURES SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "numerical_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "print(train_df[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea5526",
   "metadata": {},
   "source": [
    "## Feature Definitions and Domain Understanding\n",
    "\n",
    "Understanding the meaning and business context of each feature is essential for effective analysis. Below are the definitions of each feature in our dataset based on the bank marketing domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature definitions and categories\n",
    "feature_definitions = {\n",
    "    'id': 'Unique identifier for each customer',\n",
    "    'age': 'Age of the customer in years',\n",
    "    'job': 'Type of job/occupation of the customer',\n",
    "    'marital': 'Marital status of the customer',\n",
    "    'education': 'Education level of the customer',\n",
    "    'default': 'Has credit in default (yes/no)',\n",
    "    'balance': 'Average yearly balance in euros',\n",
    "    'housing': 'Has housing loan (yes/no)',\n",
    "    'loan': 'Has personal loan (yes/no)',\n",
    "    'contact': 'Contact communication type',\n",
    "    'day': 'Last contact day of the month',\n",
    "    'month': 'Last contact month of year',\n",
    "    'duration': 'Last contact duration in seconds',\n",
    "    'campaign': 'Number of contacts performed during this campaign',\n",
    "    'pdays': 'Number of days since previous campaign contact (-1 means never contacted)',\n",
    "    'previous': 'Number of contacts performed before this campaign',\n",
    "    'poutcome': 'Outcome of the previous marketing campaign',\n",
    "    'y': 'Target variable - has the client subscribed to a term deposit (yes=1/no=0)'\n",
    "}\n",
    "\n",
    "# Categorize features by type\n",
    "feature_categories = {\n",
    "    'Demographic': ['age', 'job', 'marital', 'education'],\n",
    "    'Financial': ['default', 'balance', 'housing', 'loan'],\n",
    "    'Campaign_Contact': ['contact', 'day', 'month', 'duration'],\n",
    "    'Campaign_History': ['campaign', 'pdays', 'previous', 'poutcome'],\n",
    "    'Target': ['y']\n",
    "}\n",
    "\n",
    "print(\"FEATURE DEFINITIONS\")\n",
    "print(\"=\"*80)\n",
    "for feature, definition in feature_definitions.items():\n",
    "    print(f\"{feature:12} : {definition}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"FEATURE CATEGORIES\")\n",
    "print(\"=\"*80)\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"{category:15} : {', '.join(features)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove ID and target from analysis features\n",
    "if 'id' in numerical_features:\n",
    "    numerical_features.remove('id')\n",
    "if 'y' in numerical_features:\n",
    "    target_col = 'y'\n",
    "    numerical_features.remove('y')\n",
    "\n",
    "print(\"FEATURE TYPE CLASSIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Categorical Features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Numerical Features ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"Target Feature: {target_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bee05f",
   "metadata": {},
   "source": [
    "## Target Variable Analysis\n",
    "\n",
    "The target variable represents the success of the marketing campaign. Understanding its distribution is crucial for model selection and evaluation strategy. We will analyze the class balance and implications for our modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "target_counts = train_df['y'].value_counts()\n",
    "target_proportions = train_df['y'].value_counts(normalize=True)\n",
    "\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Class 0 (No subscription): {target_counts[0]:,} ({target_proportions[0]:.2%})\")\n",
    "print(f\"Class 1 (Subscription): {target_counts[1]:,} ({target_proportions[1]:.2%})\")\n",
    "print(f\"Total samples: {target_counts.sum():,}\")\n",
    "print(f\"Class imbalance ratio: {target_counts[0]/target_counts[1]:.2f}:1\")\n",
    "\n",
    "# Create visualization for target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar plot\n",
    "target_counts.plot(kind='bar', ax=axes[0], color=['lightcoral', 'lightblue'])\n",
    "axes[0].set_title('Target Variable Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Target Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(['No Subscription (0)', 'Subscription (1)'], rotation=0)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    axes[0].text(i, v + 5000, f'{v:,}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(target_counts.values, labels=['No Subscription (0)', 'Subscription (1)'], \n",
    "           autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightblue'])\n",
    "axes[1].set_title('Target Variable Distribution (Proportion)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical significance check\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASS IMBALANCE IMPLICATIONS:\")\n",
    "print(\"=\"*50)\n",
    "if target_proportions[1] < 0.1:\n",
    "    print(\"- Severely imbalanced dataset (minority class < 10%)\")\n",
    "    print(\"- Consider using stratified sampling and appropriate evaluation metrics\")\n",
    "    print(\"- SMOTE or other oversampling techniques may be beneficial\")\n",
    "elif target_proportions[1] < 0.3:\n",
    "    print(\"- Moderately imbalanced dataset (minority class < 30%)\")\n",
    "    print(\"- Use stratified cross-validation and balanced evaluation metrics\")\n",
    "    print(\"- Consider class weights in model training\")\n",
    "else:\n",
    "    print(\"- Relatively balanced dataset\")\n",
    "    print(\"- Standard evaluation approaches should work well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1bf7cf",
   "metadata": {},
   "source": [
    "## Categorical Features Analysis\n",
    "\n",
    "Categorical features often contain valuable insights about customer segments and their relationship with the target variable. We will analyze the distribution of each categorical feature and examine their relationship with campaign success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c28172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "print(\"CATEGORICAL FEATURES OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "categorical_stats = []\n",
    "for col in categorical_features:\n",
    "    unique_count = train_df[col].nunique()\n",
    "    most_common = train_df[col].mode()[0]\n",
    "    most_common_freq = train_df[col].value_counts().iloc[0]\n",
    "    most_common_pct = (most_common_freq / len(train_df)) * 100\n",
    "    \n",
    "    categorical_stats.append({\n",
    "        'Feature': col,\n",
    "        'Unique_Values': unique_count,\n",
    "        'Most_Common': most_common,\n",
    "        'Most_Common_Count': most_common_freq,\n",
    "        'Most_Common_Percentage': round(most_common_pct, 2)\n",
    "    })\n",
    "\n",
    "categorical_df = pd.DataFrame(categorical_stats)\n",
    "print(categorical_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Detailed analysis of each categorical feature\n",
    "for col in categorical_features:\n",
    "    print(f\"FEATURE: {col.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    value_counts = train_df[col].value_counts()\n",
    "    print(\"Value distribution:\")\n",
    "    for value, count in value_counts.items():\n",
    "        percentage = (count / len(train_df)) * 100\n",
    "        print(f\"  {value}: {count:,} ({percentage:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "# Create visualizations for categorical features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    if i < len(axes):\n",
    "        value_counts = train_df[col].value_counts()\n",
    "        \n",
    "        # Create bar plot\n",
    "        value_counts.plot(kind='bar', ax=axes[i], color='lightblue', alpha=0.7)\n",
    "        axes[i].set_title(f'{col.title()} Distribution', fontweight='bold')\n",
    "        axes[i].set_xlabel(col.title())\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add count labels on bars\n",
    "        for j, v in enumerate(value_counts.values):\n",
    "            if v > 1000:  # Only show labels for significant bars\n",
    "                axes[i].text(j, v + 1000, f'{v:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa90e07",
   "metadata": {},
   "source": [
    "## Numerical Features Analysis\n",
    "\n",
    "Numerical features provide quantitative insights into customer characteristics and campaign interactions. We will examine their distributions, identify outliers, and assess their statistical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc43000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of numerical features\n",
    "print(\"NUMERICAL FEATURES STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(train_df[numerical_features].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "print(\"OUTLIER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = []\n",
    "for col in numerical_features:\n",
    "    Q1 = train_df[col].quantile(0.25)\n",
    "    Q3 = train_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = train_df[(train_df[col] < lower_bound) | (train_df[col] > upper_bound)][col]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percentage = (outlier_count / len(train_df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Q1': Q1,\n",
    "        'Q3': Q3,\n",
    "        'IQR': IQR,\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound,\n",
    "        'Outlier_Count': outlier_count,\n",
    "        'Outlier_Percentage': round(outlier_percentage, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df)\n",
    "\n",
    "# Distribution analysis with histograms\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    if i < len(axes):\n",
    "        # Create histogram\n",
    "        axes[i].hist(train_df[col], bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[i].set_title(f'{col.title()} Distribution', fontweight='bold')\n",
    "        axes[i].set_xlabel(col.title())\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add statistical information\n",
    "        mean_val = train_df[col].mean()\n",
    "        median_val = train_df[col].median()\n",
    "        axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        axes[i].axvline(median_val, color='blue', linestyle='--', label=f'Median: {median_val:.2f}')\n",
    "        axes[i].legend()\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(numerical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Box plots for outlier visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    if i < len(axes):\n",
    "        axes[i].boxplot(train_df[col])\n",
    "        axes[i].set_title(f'{col.title()} Box Plot', fontweight='bold')\n",
    "        axes[i].set_ylabel(col.title())\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(numerical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3abd7",
   "metadata": {},
   "source": [
    "## Bivariate Analysis: Features vs Target\n",
    "\n",
    "Understanding the relationship between individual features and the target variable is crucial for feature selection and model interpretation. We will examine how each feature correlates with campaign success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c09dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features vs Target analysis\n",
    "print(\"CATEGORICAL FEATURES vs TARGET ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "categorical_target_analysis = []\n",
    "\n",
    "for col in categorical_features:\n",
    "    # Create crosstab\n",
    "    crosstab = pd.crosstab(train_df[col], train_df['y'], normalize='index')\n",
    "    \n",
    "    # Chi-square test for independence\n",
    "    chi2, p_value, dof, expected = chi2_contingency(pd.crosstab(train_df[col], train_df['y']))\n",
    "    \n",
    "    # Calculate success rate for each category\n",
    "    success_rates = train_df.groupby(col)['y'].agg(['count', 'sum', 'mean']).round(4)\n",
    "    success_rates['success_rate_pct'] = (success_rates['mean'] * 100).round(2)\n",
    "    \n",
    "    print(f\"\\nFEATURE: {col.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Success rates by category:\")\n",
    "    print(success_rates)\n",
    "    print(f\"Chi-square test p-value: {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Result: Statistically significant association with target\")\n",
    "    else:\n",
    "        print(\"Result: No significant association with target\")\n",
    "    \n",
    "    # Store analysis results\n",
    "    categorical_target_analysis.append({\n",
    "        'Feature': col,\n",
    "        'Chi2_statistic': chi2,\n",
    "        'P_value': p_value,\n",
    "        'Significant': p_value < 0.05,\n",
    "        'Max_success_rate': success_rates['mean'].max(),\n",
    "        'Min_success_rate': success_rates['mean'].min(),\n",
    "        'Rate_difference': success_rates['mean'].max() - success_rates['mean'].min()\n",
    "    })\n",
    "\n",
    "# Create summary dataframe\n",
    "categorical_analysis_df = pd.DataFrame(categorical_target_analysis)\n",
    "categorical_analysis_df = categorical_analysis_df.sort_values('Rate_difference', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORICAL FEATURES IMPORTANCE RANKING\")\n",
    "print(\"=\"*80)\n",
    "print(categorical_analysis_df)\n",
    "\n",
    "# Visualize categorical features vs target\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    if i < len(axes):\n",
    "        # Calculate success rates\n",
    "        success_rates = train_df.groupby(col)['y'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        success_rates.plot(kind='bar', ax=axes[i], color='lightcoral', alpha=0.7)\n",
    "        axes[i].set_title(f'{col.title()} vs Success Rate', fontweight='bold')\n",
    "        axes[i].set_xlabel(col.title())\n",
    "        axes[i].set_ylabel('Success Rate')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for j, v in enumerate(success_rates.values):\n",
    "            axes[i].text(j, v + 0.005, f'{v:.2%}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ca405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features vs Target analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NUMERICAL FEATURES vs TARGET ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numerical_target_analysis = []\n",
    "\n",
    "for col in numerical_features:\n",
    "    # Calculate correlation with target\n",
    "    correlation = train_df[col].corr(train_df['y'])\n",
    "    \n",
    "    # Statistical comparison between success and failure groups\n",
    "    success_group = train_df[train_df['y'] == 1][col]\n",
    "    failure_group = train_df[train_df['y'] == 0][col]\n",
    "    \n",
    "    # T-test for difference in means\n",
    "    t_stat, p_value = stats.ttest_ind(success_group, failure_group)\n",
    "    \n",
    "    # Calculate statistics for each group\n",
    "    success_stats = {\n",
    "        'mean': success_group.mean(),\n",
    "        'median': success_group.median(),\n",
    "        'std': success_group.std()\n",
    "    }\n",
    "    \n",
    "    failure_stats = {\n",
    "        'mean': failure_group.mean(),\n",
    "        'median': failure_group.median(),\n",
    "        'std': failure_group.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFEATURE: {col.upper()}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Correlation with target: {correlation:.4f}\")\n",
    "    print(f\"Success group - Mean: {success_stats['mean']:.2f}, Median: {success_stats['median']:.2f}\")\n",
    "    print(f\"Failure group - Mean: {failure_stats['mean']:.2f}, Median: {failure_stats['median']:.2f}\")\n",
    "    print(f\"T-test p-value: {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Result: Statistically significant difference between groups\")\n",
    "    else:\n",
    "        print(\"Result: No significant difference between groups\")\n",
    "    \n",
    "    numerical_target_analysis.append({\n",
    "        'Feature': col,\n",
    "        'Correlation': correlation,\n",
    "        'T_test_pvalue': p_value,\n",
    "        'Significant': p_value < 0.05,\n",
    "        'Success_mean': success_stats['mean'],\n",
    "        'Failure_mean': failure_stats['mean'],\n",
    "        'Mean_difference': success_stats['mean'] - failure_stats['mean']\n",
    "    })\n",
    "\n",
    "# Create summary dataframe\n",
    "numerical_analysis_df = pd.DataFrame(numerical_target_analysis)\n",
    "numerical_analysis_df = numerical_analysis_df.sort_values('Correlation', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NUMERICAL FEATURES IMPORTANCE RANKING\")\n",
    "print(\"=\"*80)\n",
    "print(numerical_analysis_df)\n",
    "\n",
    "# Visualize numerical features vs target with box plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    if i < len(axes):\n",
    "        # Create box plot grouped by target\n",
    "        data_to_plot = [train_df[train_df['y'] == 0][col].values, \n",
    "                       train_df[train_df['y'] == 1][col].values]\n",
    "        \n",
    "        box_plot = axes[i].boxplot(data_to_plot, labels=['No Success (0)', 'Success (1)'])\n",
    "        axes[i].set_title(f'{col.title()} by Target', fontweight='bold')\n",
    "        axes[i].set_xlabel('Target')\n",
    "        axes[i].set_ylabel(col.title())\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplots\n",
    "for i in range(len(numerical_features), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d743355",
   "metadata": {},
   "source": [
    "## Correlation Analysis and Feature Relationships\n",
    "\n",
    "Understanding the relationships between features helps identify multicollinearity and potential feature interactions. This analysis guides our feature engineering and model selection decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "numerical_features_with_target = numerical_features + ['y']\n",
    "correlation_matrix = train_df[numerical_features_with_target].corr()\n",
    "\n",
    "print(\"CORRELATION MATRIX\")\n",
    "print(\"=\"*80)\n",
    "print(correlation_matrix.round(4))\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HIGHLY CORRELATED FEATURE PAIRS (|correlation| > 0.5)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.5 and correlation_matrix.columns[i] != 'y' and correlation_matrix.columns[j] != 'y':\n",
    "            high_corr_pairs.append({\n",
    "                'Feature_1': correlation_matrix.columns[i],\n",
    "                'Feature_2': correlation_matrix.columns[j],\n",
    "                'Correlation': corr_value\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs)\n",
    "    high_corr_df = high_corr_df.sort_values('Correlation', key=abs, ascending=False)\n",
    "    print(high_corr_df)\n",
    "else:\n",
    "    print(\"No highly correlated feature pairs found.\")\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .5}, fmt='.3f')\n",
    "plt.title('Correlation Matrix of Numerical Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance based on correlation with target\n",
    "target_correlations = correlation_matrix['y'].drop('y').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE BASED ON TARGET CORRELATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"Features ranked by absolute correlation with target:\")\n",
    "for feature, corr in target_correlations.items():\n",
    "    print(f\"{feature:15}: {corr:7.4f}\")\n",
    "\n",
    "# Visualize feature correlations with target\n",
    "plt.figure(figsize=(12, 8))\n",
    "target_correlations.plot(kind='barh', color=['red' if x < 0 else 'blue' for x in target_correlations.values])\n",
    "plt.title('Feature Correlations with Target Variable', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.ylabel('Features')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9e6f2",
   "metadata": {},
   "source": [
    "## Special Values and Data Quality Issues\n",
    "\n",
    "Banking datasets often contain special values that require careful handling. We will examine specific patterns in our data that may indicate missing values, data collection artifacts, or domain-specific encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7baaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze special values and patterns\n",
    "print(\"SPECIAL VALUES ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for -1 values in pdays (indicates no previous contact)\n",
    "pdays_negative = (train_df['pdays'] == -1).sum()\n",
    "pdays_negative_pct = (pdays_negative / len(train_df)) * 100\n",
    "\n",
    "print(f\"Records with pdays = -1 (no previous contact): {pdays_negative:,} ({pdays_negative_pct:.1f}%)\")\n",
    "\n",
    "# Analyze 'unknown' values in categorical features\n",
    "print(\"\\n'UNKNOWN' VALUES IN CATEGORICAL FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for col in categorical_features:\n",
    "    unknown_count = (train_df[col] == 'unknown').sum()\n",
    "    unknown_pct = (unknown_count / len(train_df)) * 100\n",
    "    print(f\"{col:15}: {unknown_count:,} ({unknown_pct:.1f}%)\")\n",
    "\n",
    "# Check for zero values in numerical features\n",
    "print(\"\\nZERO VALUES IN NUMERICAL FEATURES:\")\n",
    "print(\"-\" * 50)\n",
    "for col in numerical_features:\n",
    "    zero_count = (train_df[col] == 0).sum()\n",
    "    zero_pct = (zero_count / len(train_df)) * 100\n",
    "    print(f\"{col:15}: {zero_count:,} ({zero_pct:.1f}%)\")\n",
    "\n",
    "# Analyze negative balance values\n",
    "negative_balance = (train_df['balance'] < 0).sum()\n",
    "negative_balance_pct = (negative_balance / len(train_df)) * 100\n",
    "print(f\"\\nRecords with negative balance: {negative_balance:,} ({negative_balance_pct:.1f}%)\")\n",
    "\n",
    "# Check for extreme values\n",
    "print(\"\\nEXTREME VALUES ANALYSIS:\")\n",
    "print(\"-\" * 50)\n",
    "for col in numerical_features:\n",
    "    min_val = train_df[col].min()\n",
    "    max_val = train_df[col].max()\n",
    "    mean_val = train_df[col].mean()\n",
    "    std_val = train_df[col].std()\n",
    "    \n",
    "    # Values beyond 3 standard deviations\n",
    "    extreme_lower = (train_df[col] < (mean_val - 3 * std_val)).sum()\n",
    "    extreme_upper = (train_df[col] > (mean_val + 3 * std_val)).sum()\n",
    "    total_extreme = extreme_lower + extreme_upper\n",
    "    extreme_pct = (total_extreme / len(train_df)) * 100\n",
    "    \n",
    "    print(f\"{col:15}: Min={min_val:8.2f}, Max={max_val:8.2f}, Extreme values: {total_extreme:,} ({extreme_pct:.2f}%)\")\n",
    "\n",
    "# Analyze the relationship between special values and target\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPECIAL VALUES vs TARGET ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# pdays = -1 vs target\n",
    "no_previous_contact = train_df[train_df['pdays'] == -1]\n",
    "previous_contact = train_df[train_df['pdays'] != -1]\n",
    "\n",
    "print(f\"Success rate with no previous contact: {no_previous_contact['y'].mean():.4f}\")\n",
    "print(f\"Success rate with previous contact: {previous_contact['y'].mean():.4f}\")\n",
    "\n",
    "# Unknown values vs target for each categorical feature\n",
    "print(\"\\nSUCCESS RATES FOR 'UNKNOWN' vs 'KNOWN' VALUES:\")\n",
    "print(\"-\" * 60)\n",
    "for col in categorical_features:\n",
    "    unknown_success = train_df[train_df[col] == 'unknown']['y'].mean()\n",
    "    known_success = train_df[train_df[col] != 'unknown']['y'].mean()\n",
    "    print(f\"{col:15}: Unknown={unknown_success:.4f}, Known={known_success:.4f}\")\n",
    "\n",
    "# Visualize special values impact\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# pdays distribution\n",
    "axes[0, 0].hist(train_df[train_df['pdays'] != -1]['pdays'], bins=50, alpha=0.7, color='lightblue')\n",
    "axes[0, 0].set_title('Distribution of pdays (excluding -1 values)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Days since previous contact')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Balance distribution including negatives\n",
    "axes[0, 1].hist(train_df['balance'], bins=50, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('Balance Distribution (including negatives)', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Balance')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', label='Zero balance')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Unknown values count by feature\n",
    "unknown_counts = []\n",
    "for col in categorical_features:\n",
    "    unknown_counts.append((train_df[col] == 'unknown').sum())\n",
    "\n",
    "axes[1, 0].bar(categorical_features, unknown_counts, color='lightcoral', alpha=0.7)\n",
    "axes[1, 0].set_title('Count of \"Unknown\" Values by Feature', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Features')\n",
    "axes[1, 0].set_ylabel('Count of Unknown Values')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Success rate comparison for pdays\n",
    "pdays_groups = ['No Previous Contact', 'Previous Contact']\n",
    "pdays_success_rates = [no_previous_contact['y'].mean(), previous_contact['y'].mean()]\n",
    "\n",
    "axes[1, 1].bar(pdays_groups, pdays_success_rates, color=['lightblue', 'lightgreen'], alpha=0.7)\n",
    "axes[1, 1].set_title('Success Rate: Previous Contact vs No Previous Contact', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Contact History')\n",
    "axes[1, 1].set_ylabel('Success Rate')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(pdays_success_rates):\n",
    "    axes[1, 1].text(i, v + 0.005, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e4fb5",
   "metadata": {},
   "source": [
    "## Key Insights and Conclusions from EDA\n",
    "\n",
    "Based on our comprehensive exploratory data analysis, we have identified several important patterns and insights that will guide our modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize key insights from EDA\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"   - Training samples: {len(train_df):,}\")\n",
    "print(f\"   - Test samples: {len(test_df):,}\")\n",
    "print(f\"   - Features: {len(train_df.columns)-1} (excluding target)\")\n",
    "print(f\"   - Target distribution: {train_df['y'].value_counts()[0]:,} negative, {train_df['y'].value_counts()[1]:,} positive\")\n",
    "print(f\"   - Class imbalance ratio: {train_df['y'].value_counts()[0]/train_df['y'].value_counts()[1]:.1f}:1\")\n",
    "\n",
    "print(\"\\n2. DATA QUALITY:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   - No missing values detected in standard sense\")\n",
    "print(\"   - Special encoding patterns identified:\")\n",
    "print(f\"     * 'unknown' values in categorical features\")\n",
    "print(f\"     * -1 values in 'pdays' (no previous contact)\")\n",
    "print(f\"     * Negative balance values present\")\n",
    "\n",
    "print(\"\\n3. MOST PREDICTIVE FEATURES (based on target correlation/association):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Get top categorical features by chi-square significance and rate difference\n",
    "if 'categorical_analysis_df' in locals():\n",
    "    top_categorical = categorical_analysis_df.head(3)['Feature'].tolist()\n",
    "    print(f\"   Categorical: {', '.join(top_categorical)}\")\n",
    "\n",
    "# Get top numerical features by correlation\n",
    "if 'target_correlations' in locals():\n",
    "    top_numerical = target_correlations.head(3).index.tolist()\n",
    "    print(f\"   Numerical: {', '.join(top_numerical)}\")\n",
    "\n",
    "print(\"\\n4. POTENTIAL DATA ISSUES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   - High percentage of 'unknown' values in some categorical features\")\n",
    "print(\"   - Outliers present in numerical features\")\n",
    "print(\"   - Potential multicollinearity between related features\")\n",
    "\n",
    "print(\"\\n5. BUSINESS INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"   - Previous campaign outcome strongly influences success\")\n",
    "print(\"   - Contact method and timing appear important\")\n",
    "print(\"   - Customer demographics show varying success rates\")\n",
    "print(\"   - Financial status indicators may be predictive\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "next_steps = [\n",
    "    \"Feature Engineering:\",\n",
    "    \"  - Handle 'unknown' values appropriately (separate category vs imputation)\",\n",
    "    \"  - Create interaction features between highly predictive variables\",\n",
    "    \"  - Engineer temporal features from month/day information\",\n",
    "    \"  - Create binned versions of continuous variables\",\n",
    "    \"  - Develop campaign intensity and customer lifecycle features\",\n",
    "    \"\",\n",
    "    \"Data Preprocessing:\",\n",
    "    \"  - Implement appropriate scaling for numerical features\",\n",
    "    \"  - Encode categorical variables (target encoding for high cardinality)\",\n",
    "    \"  - Handle outliers through capping or transformation\",\n",
    "    \"  - Address class imbalance through sampling or class weights\",\n",
    "    \"\",\n",
    "    \"Model Development:\",\n",
    "    \"  - Start with gradient boosting models (LightGBM, XGBoost)\",\n",
    "    \"  - Implement proper cross-validation strategy\",\n",
    "    \"  - Build ensemble of diverse models\",\n",
    "    \"  - Focus on features showing strong target association\",\n",
    "    \"\",\n",
    "    \"Validation Strategy:\",\n",
    "    \"  - Use stratified cross-validation due to class imbalance\",\n",
    "    \"  - Monitor for overfitting with early stopping\",\n",
    "    \"  - Validate on multiple metrics (AUC, precision, recall)\",\n",
    "    \"  - Perform adversarial validation for train/test similarity\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f73691",
   "metadata": {},
   "source": [
    "# Feature Engineering and Data Preprocessing\n",
    "\n",
    "Based on our comprehensive EDA, we now implement targeted feature engineering strategies to improve model performance. Our analysis revealed key patterns in special values, categorical relationships, and numerical distributions that guide our preprocessing approach.\n",
    "\n",
    "## Feature Engineering Strategy\n",
    "\n",
    "Our feature engineering approach focuses on:\n",
    "1. Handling special values and unknown categories appropriately\n",
    "2. Creating meaningful interaction features based on domain knowledge\n",
    "3. Engineering temporal and cyclical features from date information\n",
    "4. Developing customer segmentation and campaign intensity metrics\n",
    "5. Addressing class imbalance and outlier management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265b81a",
   "metadata": {},
   "source": [
    "## Data Preparation and Copy Creation\n",
    "\n",
    "We start by creating working copies of our datasets to preserve the original data and prepare for feature engineering transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88176b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copies of the datasets\n",
    "train_processed = train_df.copy()\n",
    "test_processed = test_df.copy()\n",
    "\n",
    "print(\"DATASET PREPARATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training dataset shape: {train_processed.shape}\")\n",
    "print(f\"Test dataset shape: {test_processed.shape}\")\n",
    "\n",
    "# Store original feature lists for reference\n",
    "original_features = [col for col in train_processed.columns if col not in ['id', 'y']]\n",
    "print(f\"Original features count: {len(original_features)}\")\n",
    "print(f\"Original features: {original_features}\")\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_processed.drop(['y'], axis=1)\n",
    "y_train = train_processed['y']\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_train.shape}\")\n",
    "print(f\"Target vector shape: {y_train.shape}\")\n",
    "print(f\"Test matrix shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f2773",
   "metadata": {},
   "source": [
    "## Special Values and Missing Data Handling\n",
    "\n",
    "Based on our EDA findings, we identified several special encoding patterns that require careful handling. We will create indicator features for these patterns and transform them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_special_values(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Handle special values and create indicator features\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original data\n",
    "    train_clean = df_train.copy()\n",
    "    test_clean = df_test.copy()\n",
    "    \n",
    "    print(\"HANDLING SPECIAL VALUES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Handle pdays = -1 (no previous contact)\n",
    "    print(\"1. Processing 'pdays' feature:\")\n",
    "    print(f\"   - Records with pdays = -1: {(train_clean['pdays'] == -1).sum():,}\")\n",
    "    \n",
    "    # Create indicator for no previous contact\n",
    "    train_clean['no_previous_contact'] = (train_clean['pdays'] == -1).astype(int)\n",
    "    test_clean['no_previous_contact'] = (test_clean['pdays'] == -1).astype(int)\n",
    "    \n",
    "    # Transform pdays: replace -1 with a reasonable value (e.g., 999 or median of positive values)\n",
    "    pdays_positive_median = train_clean[train_clean['pdays'] > 0]['pdays'].median()\n",
    "    train_clean['pdays_transformed'] = train_clean['pdays'].replace(-1, 999)  # Large value indicating \"no contact\"\n",
    "    test_clean['pdays_transformed'] = test_clean['pdays'].replace(-1, 999)\n",
    "    \n",
    "    print(f\"   - Created 'no_previous_contact' indicator\")\n",
    "    print(f\"   - Created 'pdays_transformed' with -1 replaced by 999\")\n",
    "    \n",
    "    # 2. Handle 'unknown' values in categorical features\n",
    "    print(\"\\n2. Processing 'unknown' values in categorical features:\")\n",
    "    categorical_cols = train_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        unknown_count = (train_clean[col] == 'unknown').sum()\n",
    "        unknown_pct = (unknown_count / len(train_clean)) * 100\n",
    "        \n",
    "        if unknown_count > 0:\n",
    "            print(f\"   - {col}: {unknown_count:,} unknown values ({unknown_pct:.1f}%)\")\n",
    "            \n",
    "            # Create indicator for unknown values\n",
    "            train_clean[f'{col}_is_unknown'] = (train_clean[col] == 'unknown').astype(int)\n",
    "            test_clean[f'{col}_is_unknown'] = (test_clean[col] == 'unknown').astype(int)\n",
    "            \n",
    "            # Keep 'unknown' as a separate category (don't impute)\n",
    "            # This preserves the information that the value was unknown\n",
    "    \n",
    "    # 3. Handle negative balance\n",
    "    print(\"\\n3. Processing negative balance values:\")\n",
    "    negative_balance_count = (train_clean['balance'] < 0).sum()\n",
    "    print(f\"   - Records with negative balance: {negative_balance_count:,}\")\n",
    "    \n",
    "    # Create indicator for negative balance\n",
    "    train_clean['has_negative_balance'] = (train_clean['balance'] < 0).astype(int)\n",
    "    test_clean['has_negative_balance'] = (test_clean['balance'] < 0).astype(int)\n",
    "    \n",
    "    # Create absolute balance feature\n",
    "    train_clean['balance_abs'] = train_clean['balance'].abs()\n",
    "    test_clean['balance_abs'] = test_clean['balance'].abs()\n",
    "    \n",
    "    print(f\"   - Created 'has_negative_balance' indicator\")\n",
    "    print(f\"   - Created 'balance_abs' with absolute values\")\n",
    "    \n",
    "    # 4. Handle zero values in key features\n",
    "    print(\"\\n4. Processing zero values:\")\n",
    "    zero_features = ['duration', 'campaign', 'previous']\n",
    "    \n",
    "    for col in zero_features:\n",
    "        zero_count = (train_clean[col] == 0).sum()\n",
    "        if zero_count > 0:\n",
    "            zero_pct = (zero_count / len(train_clean)) * 100\n",
    "            print(f\"   - {col}: {zero_count:,} zero values ({zero_pct:.1f}%)\")\n",
    "            \n",
    "            # Create indicator for zero values\n",
    "            train_clean[f'{col}_is_zero'] = (train_clean[col] == 0).astype(int)\n",
    "            test_clean[f'{col}_is_zero'] = (test_clean[col] == 0).astype(int)\n",
    "    \n",
    "    return train_clean, test_clean\n",
    "\n",
    "# Apply special values handling\n",
    "X_train_processed, X_test_processed = handle_special_values(X_train, X_test)\n",
    "\n",
    "print(f\"\\nSHAPE AFTER SPECIAL VALUES HANDLING:\")\n",
    "print(f\"Training set: {X_train_processed.shape}\")\n",
    "print(f\"Test set: {X_test_processed.shape}\")\n",
    "\n",
    "# Show new features created\n",
    "original_cols = set(X_train.columns)\n",
    "new_cols = set(X_train_processed.columns) - original_cols\n",
    "print(f\"\\nNew features created: {len(new_cols)}\")\n",
    "print(f\"New features: {sorted(list(new_cols))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa84716",
   "metadata": {},
   "source": [
    "## Temporal and Cyclical Feature Engineering\n",
    "\n",
    "Time-based features often contain valuable patterns in marketing campaigns. We will engineer features from the 'month' and 'day' information to capture seasonal and cyclical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_features(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Create temporal and cyclical features from month and day information\n",
    "    \"\"\"\n",
    "    train_temp = df_train.copy()\n",
    "    test_temp = df_test.copy()\n",
    "    \n",
    "    print(\"CREATING TEMPORAL FEATURES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Month mappings\n",
    "    month_mapping = {\n",
    "        'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "        'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "    }\n",
    "    \n",
    "    # 1. Convert month names to numbers\n",
    "    train_temp['month_num'] = train_temp['month'].map(month_mapping)\n",
    "    test_temp['month_num'] = test_temp['month'].map(month_mapping)\n",
    "    \n",
    "    # 2. Create cyclical features for month (captures seasonality)\n",
    "    train_temp['month_sin'] = np.sin(2 * np.pi * train_temp['month_num'] / 12)\n",
    "    train_temp['month_cos'] = np.cos(2 * np.pi * train_temp['month_num'] / 12)\n",
    "    test_temp['month_sin'] = np.sin(2 * np.pi * test_temp['month_num'] / 12)\n",
    "    test_temp['month_cos'] = np.cos(2 * np.pi * test_temp['month_num'] / 12)\n",
    "    \n",
    "    # 3. Create cyclical features for day (captures monthly cycles)\n",
    "    train_temp['day_sin'] = np.sin(2 * np.pi * train_temp['day'] / 31)\n",
    "    train_temp['day_cos'] = np.cos(2 * np.pi * train_temp['day'] / 31)\n",
    "    test_temp['day_sin'] = np.sin(2 * np.pi * test_temp['day'] / 31)\n",
    "    test_temp['day_cos'] = np.cos(2 * np.pi * test_temp['day'] / 31)\n",
    "    \n",
    "    # 4. Create seasonal categories\n",
    "    def get_season(month_num):\n",
    "        if month_num in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month_num in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month_num in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        else:\n",
    "            return 'autumn'\n",
    "    \n",
    "    train_temp['season'] = train_temp['month_num'].apply(get_season)\n",
    "    test_temp['season'] = test_temp['month_num'].apply(get_season)\n",
    "    \n",
    "    # 5. Create day categories\n",
    "    def get_day_category(day):\n",
    "        if day <= 10:\n",
    "            return 'early_month'\n",
    "        elif day <= 20:\n",
    "            return 'mid_month'\n",
    "        else:\n",
    "            return 'late_month'\n",
    "    \n",
    "    train_temp['day_category'] = train_temp['day'].apply(get_day_category)\n",
    "    test_temp['day_category'] = test_temp['day'].apply(get_day_category)\n",
    "    \n",
    "    # 6. Create quarter feature\n",
    "    train_temp['quarter'] = ((train_temp['month_num'] - 1) // 3) + 1\n",
    "    test_temp['quarter'] = ((test_temp['month_num'] - 1) // 3) + 1\n",
    "    \n",
    "    print(\"Created temporal features:\")\n",
    "    print(\"- month_num: Numerical month (1-12)\")\n",
    "    print(\"- month_sin, month_cos: Cyclical month encoding\")\n",
    "    print(\"- day_sin, day_cos: Cyclical day encoding\")\n",
    "    print(\"- season: Seasonal categories\")\n",
    "    print(\"- day_category: Early/mid/late month categories\")\n",
    "    print(\"- quarter: Quarter of the year (1-4)\")\n",
    "    \n",
    "    return train_temp, test_temp\n",
    "\n",
    "# Apply temporal feature engineering\n",
    "X_train_processed, X_test_processed = create_temporal_features(X_train_processed, X_test_processed)\n",
    "\n",
    "print(f\"\\nSHAPE AFTER TEMPORAL FEATURE ENGINEERING:\")\n",
    "print(f\"Training set: {X_train_processed.shape}\")\n",
    "print(f\"Test set: {X_test_processed.shape}\")\n",
    "\n",
    "# Show temporal feature distribution\n",
    "print(f\"\\nTEMPORAL FEATURE DISTRIBUTIONS:\")\n",
    "print(\"Season distribution:\")\n",
    "print(X_train_processed['season'].value_counts())\n",
    "print(\"\\nDay category distribution:\")\n",
    "print(X_train_processed['day_category'].value_counts())\n",
    "print(\"\\nQuarter distribution:\")\n",
    "print(X_train_processed['quarter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb2750",
   "metadata": {},
   "source": [
    "## Customer Segmentation and Domain-Specific Features\n",
    "\n",
    "Based on banking domain knowledge, we will create features that capture customer profiles, financial status, and campaign interaction patterns that are relevant for term deposit marketing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de33a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_features(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Create customer segmentation and domain-specific features\n",
    "    \"\"\"\n",
    "    train_cust = df_train.copy()\n",
    "    test_cust = df_test.copy()\n",
    "    \n",
    "    print(\"CREATING CUSTOMER SEGMENTATION FEATURES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Age-based segmentation\n",
    "    def categorize_age(age):\n",
    "        if age <= 25:\n",
    "            return 'young'\n",
    "        elif age <= 35:\n",
    "            return 'young_adult'\n",
    "        elif age <= 50:\n",
    "            return 'middle_aged'\n",
    "        elif age <= 65:\n",
    "            return 'senior'\n",
    "        else:\n",
    "            return 'elderly'\n",
    "    \n",
    "    train_cust['age_group'] = train_cust['age'].apply(categorize_age)\n",
    "    test_cust['age_group'] = test_cust['age'].apply(categorize_age)\n",
    "    \n",
    "    # 2. Balance-based segmentation\n",
    "    def categorize_balance(balance):\n",
    "        if balance < 0:\n",
    "            return 'negative'\n",
    "        elif balance == 0:\n",
    "            return 'zero'\n",
    "        elif balance <= 1000:\n",
    "            return 'low'\n",
    "        elif balance <= 5000:\n",
    "            return 'medium'\n",
    "        elif balance <= 20000:\n",
    "            return 'high'\n",
    "        else:\n",
    "            return 'very_high'\n",
    "    \n",
    "    train_cust['balance_category'] = train_cust['balance'].apply(categorize_balance)\n",
    "    test_cust['balance_category'] = test_cust['balance'].apply(categorize_balance)\n",
    "    \n",
    "    # 3. Financial stability score\n",
    "    # Combine multiple financial indicators\n",
    "    train_cust['financial_stability'] = (\n",
    "        (train_cust['default'] == 'no').astype(int) * 2 +\n",
    "        (train_cust['balance'] > 0).astype(int) +\n",
    "        (train_cust['housing'] == 'yes').astype(int) +\n",
    "        (train_cust['loan'] == 'no').astype(int)\n",
    "    )\n",
    "    test_cust['financial_stability'] = (\n",
    "        (test_cust['default'] == 'no').astype(int) * 2 +\n",
    "        (test_cust['balance'] > 0).astype(int) +\n",
    "        (test_cust['housing'] == 'yes').astype(int) +\n",
    "        (test_cust['loan'] == 'no').astype(int)\n",
    "    )\n",
    "    \n",
    "    # 4. Campaign intensity metrics\n",
    "    # Total campaign exposure\n",
    "    train_cust['total_contacts'] = train_cust['campaign'] + train_cust['previous']\n",
    "    test_cust['total_contacts'] = test_cust['campaign'] + test_cust['previous']\n",
    "    \n",
    "    # Campaign efficiency (duration per contact)\n",
    "    train_cust['duration_per_contact'] = train_cust['duration'] / (train_cust['campaign'] + 1)  # +1 to avoid division by zero\n",
    "    test_cust['duration_per_contact'] = test_cust['duration'] / (test_cust['campaign'] + 1)\n",
    "    \n",
    "    # 5. Customer lifecycle stage\n",
    "    def get_lifecycle_stage(age, marital, job):\n",
    "        if age <= 25:\n",
    "            return 'student_young'\n",
    "        elif age <= 35 and marital == 'single':\n",
    "            return 'young_professional'\n",
    "        elif age <= 45 and marital == 'married':\n",
    "            return 'family_building'\n",
    "        elif age <= 60:\n",
    "            return 'career_peak'\n",
    "        else:\n",
    "            return 'pre_retirement'\n",
    "    \n",
    "    train_cust['lifecycle_stage'] = train_cust.apply(\n",
    "        lambda x: get_lifecycle_stage(x['age'], x['marital'], x['job']), axis=1\n",
    "    )\n",
    "    test_cust['lifecycle_stage'] = test_cust.apply(\n",
    "        lambda x: get_lifecycle_stage(x['age'], x['marital'], x['job']), axis=1\n",
    "    )\n",
    "    \n",
    "    # 6. Communication effectiveness\n",
    "    # Average duration suggests how engaged the customer is\n",
    "    train_cust['communication_quality'] = np.where(\n",
    "        train_cust['duration'] > train_cust['duration'].median(), 'high_engagement', 'low_engagement'\n",
    "    )\n",
    "    test_cust['communication_quality'] = np.where(\n",
    "        test_cust['duration'] > train_cust['duration'].median(), 'high_engagement', 'low_engagement'  # Use train median for test\n",
    "    )\n",
    "    \n",
    "    # 7. Risk profile\n",
    "    def calculate_risk_profile(row):\n",
    "        risk_score = 0\n",
    "        if row['default'] == 'yes':\n",
    "            risk_score += 3\n",
    "        if row['loan'] == 'yes':\n",
    "            risk_score += 1\n",
    "        if row['balance'] < 0:\n",
    "            risk_score += 2\n",
    "        if row['job'] == 'unknown':\n",
    "            risk_score += 1\n",
    "        \n",
    "        if risk_score <= 1:\n",
    "            return 'low_risk'\n",
    "        elif risk_score <= 3:\n",
    "            return 'medium_risk'\n",
    "        else:\n",
    "            return 'high_risk'\n",
    "    \n",
    "    train_cust['risk_profile'] = train_cust.apply(calculate_risk_profile, axis=1)\n",
    "    test_cust['risk_profile'] = test_cust.apply(calculate_risk_profile, axis=1)\n",
    "    \n",
    "    # 8. Contact recency feature (for pdays)\n",
    "    def categorize_recency(pdays):\n",
    "        if pdays == -1:\n",
    "            return 'never_contacted'\n",
    "        elif pdays <= 30:\n",
    "            return 'recent'\n",
    "        elif pdays <= 180:\n",
    "            return 'medium_recency'\n",
    "        else:\n",
    "            return 'long_ago'\n",
    "    \n",
    "    train_cust['contact_recency'] = train_cust['pdays'].apply(categorize_recency)\n",
    "    test_cust['contact_recency'] = test_cust['pdays'].apply(categorize_recency)\n",
    "    \n",
    "    print(\"Created customer segmentation features:\")\n",
    "    print(\"- age_group: Age-based categories\")\n",
    "    print(\"- balance_category: Balance-based categories\")\n",
    "    print(\"- financial_stability: Composite financial score (0-5)\")\n",
    "    print(\"- total_contacts: Sum of current and previous campaign contacts\")\n",
    "    print(\"- duration_per_contact: Average call duration efficiency\")\n",
    "    print(\"- lifecycle_stage: Customer life stage based on age/marital status\")\n",
    "    print(\"- communication_quality: Engagement level based on call duration\")\n",
    "    print(\"- risk_profile: Risk assessment based on financial indicators\")\n",
    "    print(\"- contact_recency: Recency of previous campaign contact\")\n",
    "    \n",
    "    return train_cust, test_cust\n",
    "\n",
    "# Apply customer feature engineering\n",
    "X_train_processed, X_test_processed = create_customer_features(X_train_processed, X_test_processed)\n",
    "\n",
    "print(f\"\\nSHAPE AFTER CUSTOMER FEATURE ENGINEERING:\")\n",
    "print(f\"Training set: {X_train_processed.shape}\")\n",
    "print(f\"Test set: {X_test_processed.shape}\")\n",
    "\n",
    "# Show some of the new categorical features\n",
    "print(f\"\\nCUSTOMER SEGMENTATION DISTRIBUTIONS:\")\n",
    "print(\"Age group distribution:\")\n",
    "print(X_train_processed['age_group'].value_counts())\n",
    "print(\"\\nBalance category distribution:\")\n",
    "print(X_train_processed['balance_category'].value_counts())\n",
    "print(\"\\nFinancial stability distribution:\")\n",
    "print(X_train_processed['financial_stability'].value_counts())\n",
    "print(\"\\nRisk profile distribution:\")\n",
    "print(X_train_processed['risk_profile'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd398f6b",
   "metadata": {},
   "source": [
    "## Interaction Features\n",
    "\n",
    "Based on our EDA insights about the most predictive features, we will create meaningful interaction features that capture complex relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35965620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Create interaction features based on domain knowledge and EDA insights\n",
    "    \"\"\"\n",
    "    train_inter = df_train.copy()\n",
    "    test_inter = df_test.copy()\n",
    "    \n",
    "    print(\"CREATING INTERACTION FEATURES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Age and Job interaction (career stage impact)\n",
    "    train_inter['age_job'] = train_inter['age_group'] + '_' + train_inter['job']\n",
    "    test_inter['age_job'] = test_inter['age_group'] + '_' + test_inter['job']\n",
    "    \n",
    "    # 2. Balance and Housing loan interaction (financial capacity)\n",
    "    train_inter['balance_housing'] = train_inter['balance_category'] + '_' + train_inter['housing']\n",
    "    test_inter['balance_housing'] = test_inter['balance_category'] + '_' + test_inter['housing']\n",
    "    \n",
    "    # 3. Previous outcome and contact method interaction\n",
    "    train_inter['poutcome_contact'] = train_inter['poutcome'] + '_' + train_inter['contact']\n",
    "    test_inter['poutcome_contact'] = test_inter['poutcome'] + '_' + test_inter['contact']\n",
    "    \n",
    "    # 4. Duration and campaign intensity interaction\n",
    "    train_inter['duration_campaign_ratio'] = train_inter['duration'] / (train_inter['campaign'] + 1)\n",
    "    test_inter['duration_campaign_ratio'] = test_inter['duration'] / (test_inter['campaign'] + 1)\n",
    "    \n",
    "    # 5. Age and balance interaction (wealth accumulation stage)\n",
    "    train_inter['age_balance_ratio'] = train_inter['age'] / (train_inter['balance_abs'] + 1)\n",
    "    test_inter['age_balance_ratio'] = test_inter['age'] / (test_inter['balance_abs'] + 1)\n",
    "    \n",
    "    # 6. Education and job match (professional alignment)\n",
    "    def education_job_match(education, job):\n",
    "        high_education = ['tertiary']\n",
    "        professional_jobs = ['management', 'technician', 'admin.']\n",
    "        \n",
    "        if education in high_education and job in professional_jobs:\n",
    "            return 'high_match'\n",
    "        elif education == 'secondary' and job in ['services', 'blue-collar']:\n",
    "            return 'medium_match'\n",
    "        else:\n",
    "            return 'low_match'\n",
    "    \n",
    "    train_inter['education_job_match'] = train_inter.apply(\n",
    "        lambda x: education_job_match(x['education'], x['job']), axis=1\n",
    "    )\n",
    "    test_inter['education_job_match'] = test_inter.apply(\n",
    "        lambda x: education_job_match(x['education'], x['job']), axis=1\n",
    "    )\n",
    "    \n",
    "    # 7. Seasonal and demographic interaction\n",
    "    train_inter['season_age'] = train_inter['season'] + '_' + train_inter['age_group']\n",
    "    test_inter['season_age'] = test_inter['season'] + '_' + test_inter['age_group']\n",
    "    \n",
    "    # 8. Campaign timing and previous outcome\n",
    "    train_inter['month_poutcome'] = train_inter['month'] + '_' + train_inter['poutcome']\n",
    "    test_inter['month_poutcome'] = test_inter['month'] + '_' + test_inter['poutcome']\n",
    "    \n",
    "    # 9. Financial stability and contact quality\n",
    "    train_inter['stability_communication'] = (\n",
    "        train_inter['financial_stability'].astype(str) + '_' + train_inter['communication_quality']\n",
    "    )\n",
    "    test_inter['stability_communication'] = (\n",
    "        test_inter['financial_stability'].astype(str) + '_' + test_inter['communication_quality']\n",
    "    )\n",
    "    \n",
    "    # 10. Marital status and housing interaction (family financial status)\n",
    "    train_inter['marital_housing'] = train_inter['marital'] + '_' + train_inter['housing']\n",
    "    test_inter['marital_housing'] = test_inter['marital'] + '_' + test_inter['housing']\n",
    "    \n",
    "    print(\"Created interaction features:\")\n",
    "    print(\"- age_job: Age group and job type combination\")\n",
    "    print(\"- balance_housing: Balance category and housing loan status\")\n",
    "    print(\"- poutcome_contact: Previous outcome and contact method\")\n",
    "    print(\"- duration_campaign_ratio: Call efficiency per campaign contact\")\n",
    "    print(\"- age_balance_ratio: Age to balance ratio (wealth accumulation)\")\n",
    "    print(\"- education_job_match: Education and job professional alignment\")\n",
    "    print(\"- season_age: Seasonal and age group interaction\")\n",
    "    print(\"- month_poutcome: Campaign month and previous outcome\")\n",
    "    print(\"- stability_communication: Financial stability and communication quality\")\n",
    "    print(\"- marital_housing: Marital status and housing loan interaction\")\n",
    "    \n",
    "    return train_inter, test_inter\n",
    "\n",
    "# Apply interaction feature engineering\n",
    "X_train_processed, X_test_processed = create_interaction_features(X_train_processed, X_test_processed)\n",
    "\n",
    "print(f\"\\nSHAPE AFTER INTERACTION FEATURE ENGINEERING:\")\n",
    "print(f\"Training set: {X_train_processed.shape}\")\n",
    "print(f\"Test set: {X_test_processed.shape}\")\n",
    "\n",
    "# Show total number of features created\n",
    "total_original = len(original_features)\n",
    "total_current = X_train_processed.shape[1] - 1  # Subtract 1 for ID column\n",
    "features_added = total_current - total_original\n",
    "\n",
    "print(f\"\\nFEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"Original features: {total_original}\")\n",
    "print(f\"Current features: {total_current}\")\n",
    "print(f\"Features added: {features_added}\")\n",
    "print(f\"Feature expansion ratio: {total_current/total_original:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9e1a8",
   "metadata": {},
   "source": [
    "# Categorical Encoding and Numerical Scaling\n",
    "\n",
    "With our comprehensive feature engineering complete, we now need to prepare our features for machine learning algorithms. This involves encoding categorical variables and scaling numerical features appropriately.\n",
    "\n",
    "## Encoding Strategy\n",
    "\n",
    "Based on our EDA insights, we will use:\n",
    "1. **Target Encoding** for high-cardinality categorical features\n",
    "2. **One-Hot Encoding** for low-cardinality categorical features  \n",
    "3. **Standard Scaling** for numerical features\n",
    "4. **Robust Scaling** for features with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical features in processed dataset\n",
    "print(\"FEATURE TYPE IDENTIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get current feature types\n",
    "categorical_features_processed = X_train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features_processed = X_train_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove ID from numerical features\n",
    "if 'id' in numerical_features_processed:\n",
    "    numerical_features_processed.remove('id')\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_features_processed)}):\")\n",
    "for i, feature in enumerate(categorical_features_processed, 1):\n",
    "    unique_count = X_train_processed[feature].nunique()\n",
    "    print(f\"  {i:2}. {feature:25} ({unique_count:3} unique values)\")\n",
    "\n",
    "print(f\"\\nNumerical features ({len(numerical_features_processed)}):\")\n",
    "for i, feature in enumerate(numerical_features_processed, 1):\n",
    "    print(f\"  {i:2}. {feature:25}\")\n",
    "\n",
    "# Categorize features by cardinality for encoding strategy\n",
    "low_cardinality = []  # <= 10 unique values - One-hot encode\n",
    "high_cardinality = []  # > 10 unique values - Target encode\n",
    "\n",
    "for feature in categorical_features_processed:\n",
    "    unique_count = X_train_processed[feature].nunique()\n",
    "    if unique_count <= 10:\n",
    "        low_cardinality.append(feature)\n",
    "    else:\n",
    "        high_cardinality.append(feature)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ENCODING STRATEGY BY CARDINALITY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Low cardinality features (One-Hot Encoding): {len(low_cardinality)}\")\n",
    "for feature in low_cardinality:\n",
    "    unique_count = X_train_processed[feature].nunique()\n",
    "    print(f\"  - {feature}: {unique_count} categories\")\n",
    "\n",
    "print(f\"\\nHigh cardinality features (Target Encoding): {len(high_cardinality)}\")\n",
    "for feature in high_cardinality:\n",
    "    unique_count = X_train_processed[feature].nunique()\n",
    "    print(f\"  - {feature}: {unique_count} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921aca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding for High-Cardinality Features\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def target_encode_features(X_train, y_train, X_test, categorical_cols, cv_folds=5, smoothing=1.0):\n",
    "    \"\"\"\n",
    "    Perform target encoding with cross-validation to prevent overfitting\n",
    "    \"\"\"\n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "    \n",
    "    # Global target mean for smoothing\n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    print(\"APPLYING TARGET ENCODING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize KFold for cross-validation\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    for feature in categorical_cols:\n",
    "        print(f\"Encoding {feature}...\")\n",
    "        \n",
    "        # Initialize encoded feature with global mean\n",
    "        train_encoded = np.full(len(X_train), global_mean)\n",
    "        \n",
    "        # Cross-validation encoding for training set\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            # Calculate target means for this fold\n",
    "            target_means = y_train.iloc[train_idx].groupby(X_train[feature].iloc[train_idx]).mean()\n",
    "            target_counts = y_train.iloc[train_idx].groupby(X_train[feature].iloc[train_idx]).count()\n",
    "            \n",
    "            # Apply smoothing: (count * mean + smoothing * global_mean) / (count + smoothing)\n",
    "            smoothed_means = (target_counts * target_means + smoothing * global_mean) / (target_counts + smoothing)\n",
    "            \n",
    "            # Map to validation set\n",
    "            train_encoded[val_idx] = X_train[feature].iloc[val_idx].map(smoothed_means).fillna(global_mean)\n",
    "        \n",
    "        # For test set, use all training data\n",
    "        target_means = y_train.groupby(X_train[feature]).mean()\n",
    "        target_counts = y_train.groupby(X_train[feature]).count()\n",
    "        smoothed_means = (target_counts * target_means + smoothing * global_mean) / (target_counts + smoothing)\n",
    "        \n",
    "        test_encoded = X_test[feature].map(smoothed_means).fillna(global_mean)\n",
    "        \n",
    "        # Store encoded features\n",
    "        X_train_encoded[f'{feature}_target_encoded'] = train_encoded\n",
    "        X_test_encoded[f'{feature}_target_encoded'] = test_encoded\n",
    "        \n",
    "        # Show encoding statistics\n",
    "        print(f\"  - Original categories: {X_train[feature].nunique()}\")\n",
    "        print(f\"  - Encoded range: [{train_encoded.min():.4f}, {train_encoded.max():.4f}]\")\n",
    "        print(f\"  - Correlation with target: {np.corrcoef(train_encoded, y_train)[0,1]:.4f}\")\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "# Apply target encoding to high-cardinality features\n",
    "if high_cardinality:\n",
    "    X_train_target_encoded, X_test_target_encoded = target_encode_features(\n",
    "        X_train_processed, y_train, X_test_processed, high_cardinality\n",
    "    )\n",
    "    print(f\"\\nTarget encoding completed for {len(high_cardinality)} features\")\n",
    "else:\n",
    "    X_train_target_encoded = X_train_processed.copy()\n",
    "    X_test_target_encoded = X_test_processed.copy()\n",
    "    print(\"No high-cardinality features found for target encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66601c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for Low-Cardinality Features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def one_hot_encode_features(X_train, X_test, categorical_cols):\n",
    "    \"\"\"\n",
    "    Apply one-hot encoding to low-cardinality categorical features\n",
    "    \"\"\"\n",
    "    if not categorical_cols:\n",
    "        return X_train.copy(), X_test.copy()\n",
    "    \n",
    "    print(\"APPLYING ONE-HOT ENCODING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    X_train_encoded = X_train.copy()\n",
    "    X_test_encoded = X_test.copy()\n",
    "    \n",
    "    # Initialize OneHotEncoder\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    for feature in categorical_cols:\n",
    "        print(f\"One-hot encoding {feature}...\")\n",
    "        \n",
    "        # Fit on training data and transform both sets\n",
    "        train_feature = X_train[[feature]]\n",
    "        test_feature = X_test[[feature]]\n",
    "        \n",
    "        # Fit and transform\n",
    "        train_encoded = encoder.fit_transform(train_feature)\n",
    "        test_encoded = encoder.transform(test_feature)\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = encoder.get_feature_names_out([feature])\n",
    "        \n",
    "        # Create DataFrames with proper column names\n",
    "        train_encoded_df = pd.DataFrame(train_encoded, columns=feature_names, index=X_train.index)\n",
    "        test_encoded_df = pd.DataFrame(test_encoded, columns=feature_names, index=X_test.index)\n",
    "        \n",
    "        # Add to the main dataframes\n",
    "        X_train_encoded = pd.concat([X_train_encoded, train_encoded_df], axis=1)\n",
    "        X_test_encoded = pd.concat([X_test_encoded, test_encoded_df], axis=1)\n",
    "        \n",
    "        print(f\"  - Original categories: {X_train[feature].nunique()}\")\n",
    "        print(f\"  - New binary features created: {len(feature_names)}\")\n",
    "        print(f\"  - Feature names: {list(feature_names)}\")\n",
    "    \n",
    "    print(f\"\\nShape after one-hot encoding:\")\n",
    "    print(f\"  - Training: {X_train_encoded.shape}\")\n",
    "    print(f\"  - Test: {X_test_encoded.shape}\")\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "# Apply one-hot encoding to low-cardinality features\n",
    "if low_cardinality:\n",
    "    X_train_onehot, X_test_onehot = one_hot_encode_features(\n",
    "        X_train_target_encoded, X_test_target_encoded, low_cardinality\n",
    "    )\n",
    "    print(f\"\\nOne-hot encoding completed for {len(low_cardinality)} features\")\n",
    "else:\n",
    "    X_train_onehot = X_train_target_encoded.copy()\n",
    "    X_test_onehot = X_test_target_encoded.copy()\n",
    "    print(\"No low-cardinality features found for one-hot encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf230187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "def scale_numerical_features(X_train, X_test, numerical_cols, scaling_method='standard'):\n",
    "    \"\"\"\n",
    "    Scale numerical features using specified method\n",
    "    \"\"\"\n",
    "    print(\"SCALING NUMERICAL FEATURES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    if scaling_method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        print(\"Using StandardScaler (mean=0, std=1)\")\n",
    "    elif scaling_method == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "        print(\"Using RobustScaler (median=0, IQR=1)\")\n",
    "    else:\n",
    "        raise ValueError(\"scaling_method must be 'standard' or 'robust'\")\n",
    "    \n",
    "    print(f\"Scaling {len(numerical_cols)} numerical features...\")\n",
    "    \n",
    "    # Fit scaler on training data and transform both sets\n",
    "    X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "    \n",
    "    # Show scaling statistics\n",
    "    print(f\"\\nScaling statistics:\")\n",
    "    for feature in numerical_cols[:5]:  # Show first 5 features\n",
    "        original_mean = X_train[feature].mean()\n",
    "        original_std = X_train[feature].std()\n",
    "        scaled_mean = X_train_scaled[feature].mean()\n",
    "        scaled_std = X_train_scaled[feature].std()\n",
    "        \n",
    "        print(f\"  {feature:20}: Original(={original_mean:6.2f}, ={original_std:6.2f})  \"\n",
    "              f\"Scaled(={scaled_mean:6.3f}, ={scaled_std:6.3f})\")\n",
    "    \n",
    "    if len(numerical_cols) > 5:\n",
    "        print(f\"  ... and {len(numerical_cols) - 5} more features\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# Identify which features to scale (exclude ID and already encoded features)\n",
    "features_to_scale = [col for col in numerical_features_processed \n",
    "                    if col not in ['id'] and not col.endswith('_target_encoded')]\n",
    "\n",
    "print(f\"Features to scale ({len(features_to_scale)}):\")\n",
    "for feature in features_to_scale:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "# Apply scaling (use robust scaler due to outliers identified in EDA)\n",
    "X_train_scaled, X_test_scaled, numerical_scaler = scale_numerical_features(\n",
    "    X_train_onehot, X_test_onehot, features_to_scale, scaling_method='robust'\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal dataset shapes after all preprocessing:\")\n",
    "print(f\"  - Training: {X_train_scaled.shape}\")\n",
    "print(f\"  - Test: {X_test_scaled.shape}\")\n",
    "print(f\"  - Target: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68564aa0",
   "metadata": {},
   "source": [
    "## Feature Selection and Final Preparation\n",
    "\n",
    "Before model training, we need to:\n",
    "1. Remove original categorical features that have been encoded\n",
    "2. Handle any remaining high-correlation features\n",
    "3. Prepare final feature sets for modeling\n",
    "4. Create train/validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Feature Selection and Dataset Preparation\n",
    "def prepare_final_datasets(X_train, X_test, categorical_features):\n",
    "    \"\"\"\n",
    "    Prepare final datasets by removing original categorical features and \n",
    "    handling any remaining issues\n",
    "    \"\"\"\n",
    "    print(\"FINAL DATASET PREPARATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create copies\n",
    "    X_train_final = X_train.copy()\n",
    "    X_test_final = X_test.copy()\n",
    "    \n",
    "    # Remove original categorical features (keep only encoded versions)\n",
    "    features_to_remove = []\n",
    "    for feature in categorical_features:\n",
    "        if feature in X_train_final.columns:\n",
    "            features_to_remove.append(feature)\n",
    "    \n",
    "    print(f\"Removing {len(features_to_remove)} original categorical features:\")\n",
    "    for feature in features_to_remove:\n",
    "        print(f\"  - {feature}\")\n",
    "    \n",
    "    X_train_final = X_train_final.drop(columns=features_to_remove)\n",
    "    X_test_final = X_test_final.drop(columns=features_to_remove)\n",
    "    \n",
    "    # Remove ID column if present\n",
    "    if 'id' in X_train_final.columns:\n",
    "        X_train_final = X_train_final.drop(columns=['id'])\n",
    "    if 'id' in X_test_final.columns:\n",
    "        test_ids = X_test_final['id'].copy()  # Save for submission\n",
    "        X_test_final = X_test_final.drop(columns=['id'])\n",
    "    else:\n",
    "        test_ids = None\n",
    "    \n",
    "    # Ensure same columns in both datasets\n",
    "    train_cols = set(X_train_final.columns)\n",
    "    test_cols = set(X_test_final.columns)\n",
    "    \n",
    "    if train_cols != test_cols:\n",
    "        print(f\"\\nColumn mismatch detected:\")\n",
    "        print(f\"  - Training only: {train_cols - test_cols}\")\n",
    "        print(f\"  - Test only: {test_cols - train_cols}\")\n",
    "        \n",
    "        # Keep only common columns\n",
    "        common_cols = train_cols.intersection(test_cols)\n",
    "        X_train_final = X_train_final[list(common_cols)]\n",
    "        X_test_final = X_test_final[list(common_cols)]\n",
    "        print(f\"  - Using {len(common_cols)} common columns\")\n",
    "    \n",
    "    # Check for any remaining missing values\n",
    "    train_missing = X_train_final.isnull().sum().sum()\n",
    "    test_missing = X_test_final.isnull().sum().sum()\n",
    "    \n",
    "    if train_missing > 0 or test_missing > 0:\n",
    "        print(f\"\\nWarning: Found missing values - Train: {train_missing}, Test: {test_missing}\")\n",
    "        # Fill with median for numerical, mode for categorical\n",
    "        for col in X_train_final.columns:\n",
    "            if X_train_final[col].dtype in ['float64', 'int64']:\n",
    "                fill_value = X_train_final[col].median()\n",
    "                X_train_final[col].fillna(fill_value, inplace=True)\n",
    "                X_test_final[col].fillna(fill_value, inplace=True)\n",
    "            else:\n",
    "                fill_value = X_train_final[col].mode()[0] if len(X_train_final[col].mode()) > 0 else 'unknown'\n",
    "                X_train_final[col].fillna(fill_value, inplace=True)\n",
    "                X_test_final[col].fillna(fill_value, inplace=True)\n",
    "    \n",
    "    print(f\"\\nFinal dataset shapes:\")\n",
    "    print(f\"  - Training features: {X_train_final.shape}\")\n",
    "    print(f\"  - Test features: {X_test_final.shape}\")\n",
    "    print(f\"  - Feature count: {X_train_final.shape[1]}\")\n",
    "    \n",
    "    return X_train_final, X_test_final, test_ids\n",
    "\n",
    "# Prepare final datasets\n",
    "X_train_final, X_test_final, test_ids = prepare_final_datasets(\n",
    "    X_train_scaled, X_test_scaled, categorical_features_processed\n",
    ")\n",
    "\n",
    "# Show final feature list\n",
    "print(f\"\\nFinal feature list ({len(X_train_final.columns)} features):\")\n",
    "for i, feature in enumerate(X_train_final.columns, 1):\n",
    "    print(f\"  {i:2}. {feature}\")\n",
    "\n",
    "# Quick correlation check for multicollinearity\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"MULTICOLLINEARITY CHECK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate correlation matrix for final features\n",
    "final_corr_matrix = X_train_final.corr()\n",
    "\n",
    "# Find highly correlated pairs (> 0.9)\n",
    "high_corr_threshold = 0.9\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(final_corr_matrix.columns)):\n",
    "    for j in range(i+1, len(final_corr_matrix.columns)):\n",
    "        corr_value = abs(final_corr_matrix.iloc[i, j])\n",
    "        if corr_value > high_corr_threshold:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature_1': final_corr_matrix.columns[i],\n",
    "                'Feature_2': final_corr_matrix.columns[j],\n",
    "                'Correlation': final_corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs (|r| > {high_corr_threshold}):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(f\"  - {pair['Feature_1']}  {pair['Feature_2']}: {pair['Correlation']:.3f}\")\n",
    "else:\n",
    "    print(f\"No highly correlated feature pairs found (threshold: {high_corr_threshold})\")\n",
    "\n",
    "print(f\"\\nDataset ready for modeling!\")\n",
    "print(f\"Original features: {len(original_features)}\")\n",
    "print(f\"Final features: {X_train_final.shape[1]}\")\n",
    "print(f\"Feature expansion: {X_train_final.shape[1]/len(original_features):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4d843",
   "metadata": {},
   "source": [
    "# Model Development and Training\n",
    "\n",
    "With our comprehensive feature engineering and preprocessing complete, we now move to the core machine learning phase. Our approach will focus on building robust, high-performing models optimized for this binary classification task.\n",
    "\n",
    "## Modeling Strategy\n",
    "\n",
    "Based on our EDA insights and the nature of this tabular data problem, our strategy includes:\n",
    "\n",
    "1. **Gradient Boosting Models** - LightGBM and XGBoost (proven winners in tabular competitions)\n",
    "2. **Proper Cross-Validation** - Stratified CV to handle class imbalance\n",
    "3. **Hyperparameter Optimization** - Systematic tuning for optimal performance\n",
    "4. **Model Ensemble** - Combining diverse models for improved generalization\n",
    "5. **Comprehensive Evaluation** - Multiple metrics suited for imbalanced classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d97c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation Setup and Evaluation Framework\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set up cross-validation strategy\n",
    "def setup_cross_validation(n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Set up stratified cross-validation for imbalanced dataset\n",
    "    \"\"\"\n",
    "    print(\"CROSS-VALIDATION SETUP\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Use stratified CV to maintain class distribution\n",
    "    cv_strategy = StratifiedKFold(\n",
    "        n_splits=n_splits, \n",
    "        shuffle=True, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Strategy: {n_splits}-Fold Stratified Cross-Validation\")\n",
    "    print(f\"Shuffle: True, Random State: {random_state}\")\n",
    "    \n",
    "    # Verify stratification\n",
    "    fold_distributions = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train_final, y_train)):\n",
    "        train_dist = y_train.iloc[train_idx].mean()\n",
    "        val_dist = y_train.iloc[val_idx].mean()\n",
    "        fold_distributions.append({\n",
    "            'Fold': fold + 1,\n",
    "            'Train_Size': len(train_idx),\n",
    "            'Val_Size': len(val_idx),\n",
    "            'Train_Positive_%': f\"{train_dist:.3f}\",\n",
    "            'Val_Positive_%': f\"{val_dist:.3f}\"\n",
    "        })\n",
    "    \n",
    "    fold_df = pd.DataFrame(fold_distributions)\n",
    "    print(f\"\\nFold Distribution Verification:\")\n",
    "    print(fold_df)\n",
    "    \n",
    "    return cv_strategy\n",
    "\n",
    "# Comprehensive evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba=None, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with multiple metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\n{model_name.upper()} EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    # AUC if probabilities provided\n",
    "    if y_pred_proba is not None:\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        print(f\"ROC-AUC:   {auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"TN: {cm[0,0]:,}  FP: {cm[0,1]:,}\")\n",
    "    print(f\"FN: {cm[1,0]:,}  TP: {cm[1,1]:,}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': roc_auc_score(y_true, y_pred_proba) if y_pred_proba is not None else None,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Setup cross-validation\n",
    "cv_strategy = setup_cross_validation(n_splits=5)\n",
    "\n",
    "print(f\"\\nDataset ready for model training:\")\n",
    "print(f\"Features: {X_train_final.shape[1]}\")\n",
    "print(f\"Training samples: {X_train_final.shape[0]:,}\")\n",
    "print(f\"Class distribution: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d204d",
   "metadata": {},
   "source": [
    "## LightGBM Model - Primary Gradient Boosting Approach\n",
    "\n",
    "LightGBM is our primary model choice due to its excellent performance on tabular data, efficient memory usage, and built-in handling of categorical features and class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Model Training and Evaluation\n",
    "def train_lightgbm_model(X_train, y_train, cv_strategy, params=None):\n",
    "    \"\"\"\n",
    "    Train LightGBM model with cross-validation and return results\n",
    "    \"\"\"\n",
    "    print(\"TRAINING LIGHTGBM MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Default parameters optimized for binary classification\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "            'is_unbalance': True  # Handle class imbalance\n",
    "        }\n",
    "    \n",
    "    print(\"Model Parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Cross-validation training\n",
    "    cv_scores = []\n",
    "    cv_predictions = np.zeros(len(X_train))\n",
    "    cv_predictions_proba = np.zeros(len(X_train))\n",
    "    feature_importance = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train, y_train)):\n",
    "        print(f\"\\nTraining Fold {fold + 1}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        train_data = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
    "        val_data = lgb.Dataset(X_fold_val, label=y_fold_val, reference=train_data)\n",
    "        \n",
    "        # Train model\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            valid_names=['train', 'val'],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "                lgb.log_evaluation(period=0)  # Suppress detailed logging\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Predictions\n",
    "        val_pred_proba = model.predict(X_fold_val, num_iteration=model.best_iteration)\n",
    "        val_pred = (val_pred_proba > 0.5).astype(int)\n",
    "        \n",
    "        # Store predictions\n",
    "        cv_predictions[val_idx] = val_pred\n",
    "        cv_predictions_proba[val_idx] = val_pred_proba\n",
    "        \n",
    "        # Calculate fold AUC\n",
    "        fold_auc = roc_auc_score(y_fold_val, val_pred_proba)\n",
    "        cv_scores.append(fold_auc)\n",
    "        \n",
    "        # Accumulate feature importance\n",
    "        feature_importance += model.feature_importance(importance_type='gain')\n",
    "        \n",
    "        # Store model\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"  Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "    \n",
    "    # Average feature importance\n",
    "    feature_importance /= len(models)\n",
    "    \n",
    "    # Overall CV performance\n",
    "    overall_auc = roc_auc_score(y_train, cv_predictions_proba)\n",
    "    mean_cv_auc = np.mean(cv_scores)\n",
    "    std_cv_auc = np.std(cv_scores)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Individual Fold AUCs: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    print(f\"Mean CV AUC: {mean_cv_auc:.4f}  {std_cv_auc:.4f}\")\n",
    "    print(f\"Overall AUC: {overall_auc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'cv_predictions': cv_predictions,\n",
    "        'cv_predictions_proba': cv_predictions_proba,\n",
    "        'cv_scores': cv_scores,\n",
    "        'mean_auc': mean_cv_auc,\n",
    "        'std_auc': std_cv_auc,\n",
    "        'overall_auc': overall_auc,\n",
    "        'feature_importance': feature_importance,\n",
    "        'feature_names': X_train.columns.tolist()\n",
    "    }\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_results = train_lightgbm_model(X_train_final, y_train, cv_strategy)\n",
    "\n",
    "# Evaluate LightGBM predictions\n",
    "lgb_evaluation = evaluate_model(\n",
    "    y_train, \n",
    "    lgb_results['cv_predictions'], \n",
    "    lgb_results['cv_predictions_proba'],\n",
    "    \"LightGBM Cross-Validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae326b92",
   "metadata": {},
   "source": [
    "## XGBoost Model - Alternative Gradient Boosting\n",
    "\n",
    "XGBoost provides a different gradient boosting implementation that often complements LightGBM well in ensemble approaches. We'll train it with similar methodology for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d695ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model Training and Evaluation\n",
    "def train_xgboost_model(X_train, y_train, cv_strategy, params=None):\n",
    "    \"\"\"\n",
    "    Train XGBoost model with cross-validation and return results\n",
    "    \"\"\"\n",
    "    print(\"TRAINING XGBOOST MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Default parameters optimized for binary classification\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0,\n",
    "            'early_stopping_rounds': 100  # Move early stopping to constructor\n",
    "        }\n",
    "    \n",
    "    print(\"Model Parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Calculate scale_pos_weight for class imbalance\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    params['scale_pos_weight'] = scale_pos_weight\n",
    "    print(f\"  scale_pos_weight: {scale_pos_weight:.2f} (for class imbalance)\")\n",
    "    \n",
    "    # Cross-validation training\n",
    "    cv_scores = []\n",
    "    cv_predictions = np.zeros(len(X_train))\n",
    "    cv_predictions_proba = np.zeros(len(X_train))\n",
    "    feature_importance = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train, y_train)):\n",
    "        print(f\"\\nTraining Fold {fold + 1}...\")\n",
    "        \n",
    "        # Split data\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Create XGBoost model\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        \n",
    "        # Train model with validation set\n",
    "        model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            eval_set=[(X_fold_train, y_fold_train), (X_fold_val, y_fold_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Predictions\n",
    "        val_pred_proba = model.predict_proba(X_fold_val)[:, 1]\n",
    "        val_pred = model.predict(X_fold_val)\n",
    "        \n",
    "        # Store predictions\n",
    "        cv_predictions[val_idx] = val_pred\n",
    "        cv_predictions_proba[val_idx] = val_pred_proba\n",
    "        \n",
    "        # Calculate fold AUC\n",
    "        fold_auc = roc_auc_score(y_fold_val, val_pred_proba)\n",
    "        cv_scores.append(fold_auc)\n",
    "        \n",
    "        # Accumulate feature importance\n",
    "        feature_importance += model.feature_importances_\n",
    "        \n",
    "        # Store model\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"  Fold {fold + 1} AUC: {fold_auc:.4f}\")\n",
    "    \n",
    "    # Average feature importance\n",
    "    feature_importance /= len(models)\n",
    "    \n",
    "    # Overall CV performance\n",
    "    overall_auc = roc_auc_score(y_train, cv_predictions_proba)\n",
    "    mean_cv_auc = np.mean(cv_scores)\n",
    "    std_cv_auc = np.std(cv_scores)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Individual Fold AUCs: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    print(f\"Mean CV AUC: {mean_cv_auc:.4f}  {std_cv_auc:.4f}\")\n",
    "    print(f\"Overall AUC: {overall_auc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'models': models,\n",
    "        'cv_predictions': cv_predictions,\n",
    "        'cv_predictions_proba': cv_predictions_proba,\n",
    "        'cv_scores': cv_scores,\n",
    "        'mean_auc': mean_cv_auc,\n",
    "        'std_auc': std_cv_auc,\n",
    "        'overall_auc': overall_auc,\n",
    "        'feature_importance': feature_importance,\n",
    "        'feature_names': X_train.columns.tolist()\n",
    "    }\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_results = train_xgboost_model(X_train_final, y_train, cv_strategy)\n",
    "\n",
    "# Evaluate XGBoost predictions\n",
    "xgb_evaluation = evaluate_model(\n",
    "    y_train, \n",
    "    xgb_results['cv_predictions'], \n",
    "    xgb_results['cv_predictions_proba'],\n",
    "    \"XGBoost Cross-Validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9196baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "def analyze_feature_importance(lgb_results, xgb_results, top_n=20):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance from both models\n",
    "    \"\"\"\n",
    "    print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create importance DataFrames\n",
    "    lgb_importance = pd.DataFrame({\n",
    "        'feature': lgb_results['feature_names'],\n",
    "        'lgb_importance': lgb_results['feature_importance']\n",
    "    })\n",
    "    \n",
    "    xgb_importance = pd.DataFrame({\n",
    "        'feature': xgb_results['feature_names'],\n",
    "        'xgb_importance': xgb_results['feature_importance']\n",
    "    })\n",
    "    \n",
    "    # Merge importance scores\n",
    "    importance_df = pd.merge(lgb_importance, xgb_importance, on='feature')\n",
    "    \n",
    "    # Calculate average importance\n",
    "    importance_df['avg_importance'] = (importance_df['lgb_importance'] + importance_df['xgb_importance']) / 2\n",
    "    \n",
    "    # Sort by average importance\n",
    "    importance_df = importance_df.sort_values('avg_importance', ascending=False)\n",
    "    \n",
    "    print(f\"Top {top_n} Most Important Features:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Rank':<4} {'Feature':<30} {'LGB':<8} {'XGB':<8} {'Avg':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, row in importance_df.head(top_n).iterrows():\n",
    "        print(f\"{importance_df.index.get_loc(i)+1:<4} {row['feature']:<30} \"\n",
    "              f\"{row['lgb_importance']:<8.0f} {row['xgb_importance']:<8.2f} {row['avg_importance']:<8.1f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    \n",
    "    # LightGBM importance\n",
    "    top_lgb = importance_df.head(15)\n",
    "    axes[0].barh(range(len(top_lgb)), top_lgb['lgb_importance'], color='lightblue')\n",
    "    axes[0].set_yticks(range(len(top_lgb)))\n",
    "    axes[0].set_yticklabels(top_lgb['feature'])\n",
    "    axes[0].set_title('LightGBM Feature Importance', fontweight='bold')\n",
    "    axes[0].set_xlabel('Importance Score')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # XGBoost importance\n",
    "    top_xgb = importance_df.head(15)\n",
    "    axes[1].barh(range(len(top_xgb)), top_xgb['xgb_importance'], color='lightcoral')\n",
    "    axes[1].set_yticks(range(len(top_xgb)))\n",
    "    axes[1].set_yticklabels(top_xgb['feature'])\n",
    "    axes[1].set_title('XGBoost Feature Importance', fontweight='bold')\n",
    "    axes[1].set_xlabel('Importance Score')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    # Average importance\n",
    "    top_avg = importance_df.head(15)\n",
    "    axes[2].barh(range(len(top_avg)), top_avg['avg_importance'], color='lightgreen')\n",
    "    axes[2].set_yticks(range(len(top_avg)))\n",
    "    axes[2].set_yticklabels(top_avg['feature'])\n",
    "    axes[2].set_title('Average Feature Importance', fontweight='bold')\n",
    "    axes[2].set_xlabel('Average Importance Score')\n",
    "    axes[2].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Analyze feature importance\n",
    "feature_importance_df = analyze_feature_importance(lgb_results, xgb_results)\n",
    "\n",
    "# Compare model performance\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<20} {'LightGBM':<12} {'XGBoost':<12}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Mean CV AUC':<20} {lgb_results['mean_auc']:<12.4f} {xgb_results['mean_auc']:<12.4f}\")\n",
    "print(f\"{'CV AUC Std':<20} {lgb_results['std_auc']:<12.4f} {xgb_results['std_auc']:<12.4f}\")\n",
    "print(f\"{'Overall AUC':<20} {lgb_results['overall_auc']:<12.4f} {xgb_results['overall_auc']:<12.4f}\")\n",
    "\n",
    "# Determine best model\n",
    "if lgb_results['overall_auc'] > xgb_results['overall_auc']:\n",
    "    best_model_name = \"LightGBM\"\n",
    "    best_results = lgb_results\n",
    "else:\n",
    "    best_model_name = \"XGBoost\"\n",
    "    best_results = xgb_results\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name} (AUC: {best_results['overall_auc']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa248943",
   "metadata": {},
   "source": [
    "## Ensemble Model - Combining Predictions\n",
    "\n",
    "Ensemble methods often provide the best performance in Kaggle competitions by combining the strengths of different models. We'll create a weighted ensemble of our best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c54f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model Creation and Evaluation\n",
    "def create_ensemble_predictions(lgb_results, xgb_results, weights=None):\n",
    "    \"\"\"\n",
    "    Create ensemble predictions from multiple models\n",
    "    \"\"\"\n",
    "    print(\"CREATING ENSEMBLE MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if weights is None:\n",
    "        # Weight by relative performance (AUC-based)\n",
    "        lgb_weight = lgb_results['overall_auc']\n",
    "        xgb_weight = xgb_results['overall_auc']\n",
    "        total_weight = lgb_weight + xgb_weight\n",
    "        weights = [lgb_weight / total_weight, xgb_weight / total_weight]\n",
    "    \n",
    "    print(f\"Ensemble weights:\")\n",
    "    print(f\"  LightGBM: {weights[0]:.3f}\")\n",
    "    print(f\"  XGBoost:  {weights[1]:.3f}\")\n",
    "    \n",
    "    # Weighted average of probabilities\n",
    "    ensemble_proba = (\n",
    "        weights[0] * lgb_results['cv_predictions_proba'] +\n",
    "        weights[1] * xgb_results['cv_predictions_proba']\n",
    "    )\n",
    "    \n",
    "    # Convert to binary predictions\n",
    "    ensemble_pred = (ensemble_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate ensemble AUC\n",
    "    ensemble_auc = roc_auc_score(y_train, ensemble_proba)\n",
    "    \n",
    "    print(f\"\\nEnsemble Performance:\")\n",
    "    print(f\"  AUC: {ensemble_auc:.4f}\")\n",
    "    print(f\"  LightGBM AUC: {lgb_results['overall_auc']:.4f}\")\n",
    "    print(f\"  XGBoost AUC:  {xgb_results['overall_auc']:.4f}\")\n",
    "    \n",
    "    improvement_lgb = ensemble_auc - lgb_results['overall_auc']\n",
    "    improvement_xgb = ensemble_auc - xgb_results['overall_auc']\n",
    "    \n",
    "    print(f\"\\nImprovement over individual models:\")\n",
    "    print(f\"  vs LightGBM: {improvement_lgb:+.4f}\")\n",
    "    print(f\"  vs XGBoost:  {improvement_xgb:+.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': ensemble_pred,\n",
    "        'predictions_proba': ensemble_proba,\n",
    "        'auc': ensemble_auc,\n",
    "        'weights': weights\n",
    "    }\n",
    "\n",
    "# Create ensemble predictions\n",
    "ensemble_results = create_ensemble_predictions(lgb_results, xgb_results)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "ensemble_evaluation = evaluate_model(\n",
    "    y_train,\n",
    "    ensemble_results['predictions'],\n",
    "    ensemble_results['predictions_proba'],\n",
    "    \"Ensemble Model\"\n",
    ")\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# AUC comparison\n",
    "models = ['LightGBM', 'XGBoost', 'Ensemble']\n",
    "aucs = [lgb_results['overall_auc'], xgb_results['overall_auc'], ensemble_results['auc']]\n",
    "colors = ['lightblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "bars = axes[0].bar(models, aucs, color=colors, alpha=0.7)\n",
    "axes[0].set_title('Model AUC Comparison', fontweight='bold')\n",
    "axes[0].set_ylabel('AUC Score')\n",
    "axes[0].set_ylim(0.8, max(aucs) + 0.01)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, auc in zip(bars, aucs):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "                f'{auc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# ROC Curves\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Calculate ROC curves\n",
    "lgb_fpr, lgb_tpr, _ = roc_curve(y_train, lgb_results['cv_predictions_proba'])\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_train, xgb_results['cv_predictions_proba'])\n",
    "ens_fpr, ens_tpr, _ = roc_curve(y_train, ensemble_results['predictions_proba'])\n",
    "\n",
    "axes[1].plot(lgb_fpr, lgb_tpr, label=f'LightGBM (AUC = {lgb_results[\"overall_auc\"]:.4f})', color='blue')\n",
    "axes[1].plot(xgb_fpr, xgb_tpr, label=f'XGBoost (AUC = {xgb_results[\"overall_auc\"]:.4f})', color='red')\n",
    "axes[1].plot(ens_fpr, ens_tpr, label=f'Ensemble (AUC = {ensemble_results[\"auc\"]:.4f})', color='green', linewidth=2)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[1].set_title('ROC Curves Comparison', fontweight='bold')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final model selection\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL SELECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_models = {\n",
    "    'LightGBM': lgb_results,\n",
    "    'XGBoost': xgb_results,\n",
    "    'Ensemble': ensemble_results\n",
    "}\n",
    "\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "for name, results in final_models.items():\n",
    "    auc = results['auc'] if 'auc' in results else results['overall_auc']\n",
    "    print(f\"{name:<10}: AUC = {auc:.4f}\")\n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = name\n",
    "\n",
    "print(f\"\\nBest model for final predictions: {best_model} (AUC: {best_auc:.4f})\")\n",
    "\n",
    "# Store best model results for prediction\n",
    "if best_model == 'Ensemble':\n",
    "    final_model_results = ensemble_results\n",
    "    final_model_results['models'] = {\n",
    "        'lgb': lgb_results['models'],\n",
    "        'xgb': xgb_results['models'],\n",
    "        'weights': ensemble_results['weights']\n",
    "    }\n",
    "elif best_model == 'LightGBM':\n",
    "    final_model_results = lgb_results\n",
    "else:\n",
    "    final_model_results = xgb_results\n",
    "\n",
    "print(f\"\\nModel ready for test set predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a827f",
   "metadata": {},
   "source": [
    "## Test Set Predictions and Submission\n",
    "\n",
    "Now we'll use our best-performing model to make predictions on the test set and prepare the final submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ec9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Predictions and Submission File Creation\n",
    "def generate_test_predictions(models_dict, X_test, model_type='ensemble'):\n",
    "    \"\"\"\n",
    "    Generate predictions on test set using trained models\n",
    "    \"\"\"\n",
    "    print(\"GENERATING TEST SET PREDICTIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if model_type == 'ensemble':\n",
    "        print(\"Using ensemble of LightGBM and XGBoost models\")\n",
    "        \n",
    "        # Get models and weights\n",
    "        lgb_models = models_dict['models']['lgb']\n",
    "        xgb_models = models_dict['models']['xgb']\n",
    "        weights = models_dict['models']['weights']\n",
    "        \n",
    "        # Average predictions across folds for each model\n",
    "        lgb_test_preds = np.zeros(len(X_test))\n",
    "        xgb_test_preds = np.zeros(len(X_test))\n",
    "        \n",
    "        # LightGBM predictions\n",
    "        for model in lgb_models:\n",
    "            lgb_test_preds += model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        lgb_test_preds /= len(lgb_models)\n",
    "        \n",
    "        # XGBoost predictions\n",
    "        for model in xgb_models:\n",
    "            xgb_test_preds += model.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_preds /= len(xgb_models)\n",
    "        \n",
    "        # Ensemble predictions\n",
    "        test_predictions = weights[0] * lgb_test_preds + weights[1] * xgb_test_preds\n",
    "        \n",
    "        print(f\"  LightGBM average prediction: {lgb_test_preds.mean():.4f}\")\n",
    "        print(f\"  XGBoost average prediction:  {xgb_test_preds.mean():.4f}\")\n",
    "        print(f\"  Ensemble average prediction: {test_predictions.mean():.4f}\")\n",
    "        \n",
    "    elif model_type == 'lightgbm':\n",
    "        print(\"Using LightGBM models\")\n",
    "        models = models_dict['models']\n",
    "        test_predictions = np.zeros(len(X_test))\n",
    "        \n",
    "        for model in models:\n",
    "            test_predictions += model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        test_predictions /= len(models)\n",
    "        \n",
    "        print(f\"  Average prediction: {test_predictions.mean():.4f}\")\n",
    "        \n",
    "    elif model_type == 'xgboost':\n",
    "        print(\"Using XGBoost models\")\n",
    "        models = models_dict['models']\n",
    "        test_predictions = np.zeros(len(X_test))\n",
    "        \n",
    "        for model in models:\n",
    "            test_predictions += model.predict_proba(X_test)[:, 1]\n",
    "        test_predictions /= len(models)\n",
    "        \n",
    "        print(f\"  Average prediction: {test_predictions.mean():.4f}\")\n",
    "    \n",
    "    # Prediction statistics\n",
    "    print(f\"\\nPrediction Statistics:\")\n",
    "    print(f\"  Min:    {test_predictions.min():.4f}\")\n",
    "    print(f\"  Max:    {test_predictions.max():.4f}\")\n",
    "    print(f\"  Mean:   {test_predictions.mean():.4f}\")\n",
    "    print(f\"  Median: {np.median(test_predictions):.4f}\")\n",
    "    print(f\"  Std:    {test_predictions.std():.4f}\")\n",
    "    \n",
    "    # Distribution of predictions\n",
    "    pred_bins = np.histogram(test_predictions, bins=10)[0]\n",
    "    print(f\"\\nPrediction Distribution (10 bins):\")\n",
    "    bin_edges = np.linspace(0, 1, 11)\n",
    "    for i in range(len(pred_bins)):\n",
    "        print(f\"  {bin_edges[i]:.1f}-{bin_edges[i+1]:.1f}: {pred_bins[i]:,} samples\")\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "def create_submission_file(test_predictions, test_ids, filename='submission.csv'):\n",
    "    \"\"\"\n",
    "    Create submission file in Kaggle format\n",
    "    \"\"\"\n",
    "    print(f\"\\nCREATING SUBMISSION FILE: {filename}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'y': test_predictions\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"Submission file saved: {filename}\")\n",
    "    print(f\"Shape: {submission_df.shape}\")\n",
    "    print(f\"Columns: {list(submission_df.columns)}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(submission_df.head())\n",
    "    \n",
    "    # Show last few rows\n",
    "    print(f\"\\nLast 5 rows:\")\n",
    "    print(submission_df.tail())\n",
    "    \n",
    "    # Validation checks\n",
    "    print(f\"\\nValidation Checks:\")\n",
    "    print(f\"   ID range: {submission_df['id'].min()} to {submission_df['id'].max()}\")\n",
    "    print(f\"   Prediction range: {submission_df['y'].min():.4f} to {submission_df['y'].max():.4f}\")\n",
    "    print(f\"   No missing values: {submission_df.isnull().sum().sum() == 0}\")\n",
    "    print(f\"   Correct shape: {submission_df.shape[0] == len(test_ids)}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# Generate test predictions using best model\n",
    "if best_model == 'Ensemble':\n",
    "    test_predictions = generate_test_predictions(final_model_results, X_test_final, 'ensemble')\n",
    "elif best_model == 'LightGBM':\n",
    "    test_predictions = generate_test_predictions(final_model_results, X_test_final, 'lightgbm')\n",
    "else:\n",
    "    test_predictions = generate_test_predictions(final_model_results, X_test_final, 'xgboost')\n",
    "\n",
    "# Create submission file\n",
    "submission_df = create_submission_file(test_predictions, test_ids, 'submission.csv')\n",
    "\n",
    "# Visualize prediction distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Prediction histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(test_predictions, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "plt.title('Test Set Prediction Distribution', fontweight='bold')\n",
    "plt.xlabel('Prediction Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(test_predictions)\n",
    "plt.title('Test Set Prediction Box Plot', fontweight='bold')\n",
    "plt.ylabel('Prediction Probability')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION READY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final model: {best_model}\")\n",
    "print(f\"Cross-validation AUC: {best_auc:.4f}\")\n",
    "print(f\"Submission file: submission.csv\")\n",
    "print(f\"Test predictions generated for {len(test_predictions):,} samples\")\n",
    "print(\"\\nGood luck with your Kaggle submission! \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
